{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "bzfZlPsKVpAW",
    "outputId": "40b48b55-cf8b-430a-a5a8-92eb6b8400c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# run in colab\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "4DhpdhIPVpAf",
    "outputId": "a3587a0f-c112-4610-8b06-21581d478f19"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47917</th>\n",
       "      <td>47917</td>\n",
       "      <td>train</td>\n",
       "      <td>I must admit a slight disappointment with this...</td>\n",
       "      <td>pos</td>\n",
       "      <td>8126_7.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84089</th>\n",
       "      <td>84089</td>\n",
       "      <td>train</td>\n",
       "      <td>This is quite possibly one of the worst movies...</td>\n",
       "      <td>unsup</td>\n",
       "      <td>40681_0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7061</th>\n",
       "      <td>7061</td>\n",
       "      <td>test</td>\n",
       "      <td>I was prepared for a bad movie, and a bad movi...</td>\n",
       "      <td>neg</td>\n",
       "      <td>5105_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52098</th>\n",
       "      <td>52098</td>\n",
       "      <td>train</td>\n",
       "      <td>I gave this a 2 instead of a 1 only because I ...</td>\n",
       "      <td>unsup</td>\n",
       "      <td>1188_0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>394</td>\n",
       "      <td>test</td>\n",
       "      <td>There is something about this show that keeps ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10355_4.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   type  ...  label         file\n",
       "47917       47917  train  ...    pos   8126_7.txt\n",
       "84089       84089  train  ...  unsup  40681_0.txt\n",
       "7061         7061   test  ...    neg   5105_3.txt\n",
       "52098       52098  train  ...  unsup   1188_0.txt\n",
       "394           394   test  ...    neg  10355_4.txt\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reviews_df = pd.read_csv(\"/content/drive/My Drive/kaggle_reviews.csv\", encoding=\"cp1251\")\n",
    "reviews_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zUSOGVVHVpAi"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\"+punctuation+\" ]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "reviews_df[\"review\"] = reviews_df[\"review\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y6R_L6M4VpAk"
   },
   "outputs": [],
   "source": [
    "unsup_df = reviews_df.loc[reviews_df[\"label\"] == \"unsup\"]\n",
    "reviews_df = reviews_df.loc[reviews_df[\"label\"] != \"unsup\"]\n",
    "\n",
    "test_df = reviews_df.loc[reviews_df[\"type\"] == \"test\"]\n",
    "train_df = reviews_df.loc[reviews_df[\"type\"] == \"train\"]\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "val_frac = 0.8\n",
    "val_df = train_df[int(len(train_df)*val_frac):]\n",
    "train_df = train_df[:int(len(train_df)*val_frac)]\n",
    "\n",
    "train_df.to_csv('_train.csv', index=False, encoding=\"utf-8\")\n",
    "test_df.to_csv('_test.csv', index=False, encoding=\"utf-8\")\n",
    "val_df.to_csv('_val.csv', index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HtSV-qU_VpAn"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    text_list = []\n",
    "    for word in nlp(text):\n",
    "        l = word.lemma_\n",
    "        t = word.text\n",
    "        if l == \"-PRON-\":\n",
    "            w = t.lower()\n",
    "        else:\n",
    "            w = l.lower()\n",
    "        if w and not w.startswith(\" \") and not w.endswith(\" \"):\n",
    "          if \" \" in w:\n",
    "            text_list += w.split(\" \")\n",
    "          else:\n",
    "            text_list.append(w)\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qfO2QUBVpAq"
   },
   "outputs": [],
   "source": [
    "unsup_sents = [tokenizer(review) for review in unsup_df[\"review\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rHdX61exVpAt"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec(unsup_sents, size=300, window=7, min_count=3, workers=4)\n",
    "model.wv.save_word2vec_format(\"model.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MzPUbcMqVpAv"
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import Vectors\n",
    "\n",
    "vectors = Vectors(name=\"model.w2v\", cache=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yr78AR_6VpAx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Field, LabelField, TabularDataset, BucketIterator\n",
    "\n",
    "classes = {\n",
    "    'neg': 0,\n",
    "    'pos': 1\n",
    "}\n",
    "\n",
    "TEXT = Field(include_lengths=True, batch_first=True, \n",
    "             tokenize=tokenizer,\n",
    "             eos_token='<eos>',\n",
    "             lower=True)\n",
    "\n",
    "LABEL = LabelField(dtype=torch.float, use_vocab=True, preprocessing=lambda x: classes[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "v5actgADlXeg",
    "outputId": "3360b69d-77f4-457b-b807-31633d13de15"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45223</td>\n",
       "      <td>train</td>\n",
       "      <td>John Holmes is so famous, he's infamous (as th...</td>\n",
       "      <td>pos</td>\n",
       "      <td>5701_8.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29069</td>\n",
       "      <td>train</td>\n",
       "      <td>This movie is yet another in the long line of ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>2412_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36704</td>\n",
       "      <td>train</td>\n",
       "      <td>Considering that I felt like picking up a new ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>9285_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28273</td>\n",
       "      <td>train</td>\n",
       "      <td>I am a great fan of David Lynch and have every...</td>\n",
       "      <td>neg</td>\n",
       "      <td>1697_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42713</td>\n",
       "      <td>train</td>\n",
       "      <td>This movie leaves the intellectual mind thinki...</td>\n",
       "      <td>pos</td>\n",
       "      <td>3442_10.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>41669</td>\n",
       "      <td>train</td>\n",
       "      <td>This movie surprised me! Not ever having heard...</td>\n",
       "      <td>pos</td>\n",
       "      <td>2502_8.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>34762</td>\n",
       "      <td>train</td>\n",
       "      <td>And I thought The Beach was bad, with the diff...</td>\n",
       "      <td>neg</td>\n",
       "      <td>7537_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>36790</td>\n",
       "      <td>train</td>\n",
       "      <td>The plot sounded like it had promise. To be ho...</td>\n",
       "      <td>neg</td>\n",
       "      <td>9362_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>39217</td>\n",
       "      <td>train</td>\n",
       "      <td>First ever viewing: July 21, 2008&lt;br /&gt;&lt;br /&gt;V...</td>\n",
       "      <td>pos</td>\n",
       "      <td>11546_9.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>45289</td>\n",
       "      <td>train</td>\n",
       "      <td>I swear, that zombie was killed like twice, an...</td>\n",
       "      <td>pos</td>\n",
       "      <td>5761_8.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   type  ... label         file\n",
       "0           45223  train  ...   pos   5701_8.txt\n",
       "1           29069  train  ...   neg   2412_1.txt\n",
       "2           36704  train  ...   neg   9285_3.txt\n",
       "3           28273  train  ...   neg   1697_2.txt\n",
       "4           42713  train  ...   pos  3442_10.txt\n",
       "...           ...    ...  ...   ...          ...\n",
       "19995       41669  train  ...   pos   2502_8.txt\n",
       "19996       34762  train  ...   neg   7537_1.txt\n",
       "19997       36790  train  ...   neg   9362_1.txt\n",
       "19998       39217  train  ...   pos  11546_9.txt\n",
       "19999       45289  train  ...   pos   5761_8.txt\n",
       "\n",
       "[20000 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VND_2BQ_VpA0"
   },
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = TabularDataset.splits(\n",
    "    path='.', train='_train.csv',\n",
    "    validation='_val.csv', test='_test.csv', format='csv',\n",
    "    skip_header=True,\n",
    "    fields=[(None, None), (None, None), ('text', TEXT), ('label', LABEL), (None, None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0cjoWNlnOfmz"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, val_data, test_data), \n",
    "    batch_sizes=(BATCH_SIZE, BATCH_SIZE, BATCH_SIZE),\n",
    "    shuffle=True, sort=False, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjCRra7UVpA4"
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, min_freq=3, vectors=vectors)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OzpsM0WrVpA8"
   },
   "outputs": [],
   "source": [
    "class NeuralModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        self.conv_0 = nn.Conv2d(in_channels = 1, out_channels = n_filters, kernel_size = (filter_sizes[0], embedding_dim))\n",
    "        self.conv_1 = nn.Conv2d(in_channels = 1, out_channels = n_filters, kernel_size = (filter_sizes[1], embedding_dim))\n",
    "        self.conv_2 = nn.Conv2d(in_channels = 1, out_channels = n_filters, kernel_size = (filter_sizes[2], embedding_dim))\n",
    "        \n",
    "        self.out = nn.Linear(len(filter_sizes) * n_filters, 1)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embeds = self.embedding(text)        \n",
    "        embeds = embeds.unsqueeze(1)\n",
    "                \n",
    "        conved_0 = F.relu(self.conv_0(embeds).squeeze(3))\n",
    "        conved_1 = F.relu(self.conv_1(embeds).squeeze(3))\n",
    "        conved_2 = F.relu(self.conv_2(embeds).squeeze(3))\n",
    "                    \n",
    "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
    "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
    "                \n",
    "        cat = torch.cat((pooled_0, pooled_1, pooled_2), dim = 1)\n",
    "        \n",
    "        ret = self.out(cat)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCpthR56VpA_"
   },
   "outputs": [],
   "source": [
    "input_dim = len(TEXT.vocab)\n",
    "embedding_dim = 300\n",
    "n_filters = 100\n",
    "filter_sizes = [3,4,5]\n",
    "output_dim = 1\n",
    "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = NeuralModel(input_dim, embedding_dim, n_filters, filter_sizes, output_dim, pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQANBLi7VpBB"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9sj1emD8VpBD"
   },
   "outputs": [],
   "source": [
    "def bin_acc(y_pred, y):\n",
    "    rounded_pred = torch.round(torch.sigmoid(y_pred))\n",
    "    correct = (rounded_pred == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8drwZHNVpBF"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_preds = model(batch.text[0]).squeeze(1)\n",
    "        loss = criterion(y_preds, batch.label)\n",
    "        acc = bin_acc(y_preds, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            y_preds = model(batch.text[0]).squeeze(1)\n",
    "            loss = criterion(y_preds, batch.label)\n",
    "            acc = bin_acc(y_preds, batch.label)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BXCc7dwMVpBH"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Lk6dL3mVpBJ"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_iter, val_iter, optimizer,\n",
    "                criterion, num_epochs=100, es_epochs=3):\n",
    "    best_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    epoch_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
    "        valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), 'model.pt')\n",
    "            epoch_no_improve = 0\n",
    "        else:\n",
    "            epoch_no_improve += 1\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        \n",
    "        if epoch_no_improve >= es_epochs:\n",
    "            print(\"\\n\")\n",
    "            print(\"Early stopping!\")\n",
    "            print(f\"Best epoch: {best_epoch:02}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "gXxb9hFhVpBO",
    "outputId": "f616f236-3ecd-4875-fad5-37534153548e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.435 | Train Acc: 79.47%\n",
      "\t Val. Loss: 0.346 |  Val. Acc: 84.79%\n",
      "Epoch: 02 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.232 | Train Acc: 91.20%\n",
      "\t Val. Loss: 0.337 |  Val. Acc: 85.32%\n",
      "Epoch: 03 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.103 | Train Acc: 97.38%\n",
      "\t Val. Loss: 0.310 |  Val. Acc: 87.06%\n",
      "Epoch: 04 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.031 | Train Acc: 99.81%\n",
      "\t Val. Loss: 0.312 |  Val. Acc: 87.88%\n",
      "Epoch: 05 | Epoch Time: 0m 51s\n",
      "\tTrain Loss: 0.009 | Train Acc: 100.00%\n",
      "\t Val. Loss: 0.323 |  Val. Acc: 87.76%\n",
      "Epoch: 06 | Epoch Time: 0m 52s\n",
      "\tTrain Loss: 0.005 | Train Acc: 100.00%\n",
      "\t Val. Loss: 0.338 |  Val. Acc: 87.99%\n",
      "\n",
      "\n",
      "Early stopping!\n",
      "Best epoch: 03\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_iterator, valid_iterator, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "n_BXVe-wVpBS",
    "outputId": "35c1fbfa-3df9-426d-8d00-e93efdec6542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.300 | Test Acc: 87.77%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
